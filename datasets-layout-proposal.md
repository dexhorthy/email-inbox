# Drift Detection: Dead Simple

## The One Thing We Track

**Question**: Did the model change its mind about the same email?

**Data**: Store every run, group emails by content hash, compare classifications.

**Alert**: When same email gets different results across runs.

That's it.

## Simpler Structure

**Current (over-engineered):**
```
datasets/
â”œâ”€â”€ runs/run-{timestamp}/
â”‚   â”œâ”€â”€ meta.json           # ğŸ—‘ï¸ complex metadata
â”‚   â””â”€â”€ emails/{id}.json    # ğŸ—‘ï¸ full email data
â”œâ”€â”€ emails/by-hash/         # ğŸ—‘ï¸ cross-references  
â””â”€â”€ index.json             # ğŸ—‘ï¸ global index
```

**Simplified:**
```
datasets/
â””â”€â”€ {content-hash}.json    # One file per unique email
```

Each file contains:
```json
{
  "hash": "abc123",
  "subject": "Your 2FA code", 
  "from": "security@example.com",
  "classifications": [
    {"timestamp": "2025-06-07", "result": "notify_immediately"},
    {"timestamp": "2025-06-08", "result": "read_later"}  // âš ï¸ DRIFT!
  ]
}
```

**Drift detection**: Look for arrays with different `result` values.

## Benefits
- âœ… No complex directory structure  
- âœ… No redundant metadata
- âœ… Drift detection in one file scan
- âœ… Easy to implement dashboard